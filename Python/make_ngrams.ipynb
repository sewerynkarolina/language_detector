{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tworzy macierz słów dla 1,2,3 gramów do ostatecznego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../Datasets/df_lem.pkl\")\n",
    "df = df[df['text_cc']!=\"\"]\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = ['Americans','American',\n",
    "'American','Arab' ,\n",
    "'Austrians', 'Bangladeshi','British',\n",
    "'Czechs' ,'Chinese',\n",
    "'Chinese','English',\n",
    "'French' ,'French',\n",
    "'French','German' ,\n",
    "'Germans' ,'Greeks' ,\n",
    "'Hungarians','Italian',\n",
    "'Italians','Japanese' ,\n",
    "'Lithuanians' ,'Malays','Poles' ,\n",
    "'Polish' ,'Portuguese',\n",
    "'Portugiese','Russian','Russian',\n",
    "'Russians','Slovakians',\n",
    "'Spanish','Spanish',\n",
    "'Turkish','Turks','Vietnamese','Chinese',\n",
    "'Bangladeshi','China','Hungary','Vietnam','Greece',\n",
    "'Poland','Malaysia',\n",
    "'Georgia','UK',\n",
    "'Japan','Bangladesh',\n",
    "'USA','Japan',\n",
    "'Russia','China',\n",
    "'Kuwait','United Arab Emirates',\n",
    "'Oman','Saudi Arabia',\n",
    "'Bahrain','Qatar',\n",
    "'USA','Russia', 'Austria',\n",
    "'UK','Malaysia','France',\n",
    "'USA','sogbesan/Poland','Lithuania',\n",
    "'Germany','UK','Turkey','CzechRepublic',\n",
    "'Kuwait','Vietnam','Spain']\n",
    "\n",
    "dest = ['USA','USA','USA','UnitedArabEmirates','Austria','Bangladesh',\n",
    "'UK','CzechRepublic','China','China','UK','France','France','France','Germany','Germany',\n",
    "'Greece','Hungary', 'Italy','Italy','Japan','Lithuania','Malaysia','Poland',\n",
    "'Poland','Portugal','Portugal','Russia','Russia','Russia', 'Slovakia','Spain','Spain','Turkey',\n",
    "'Turkey','Vietnam','China','Bangladesh','China','Hungary','Vietnam','Greece','Poland','Malaysia',\n",
    "'Georgia','UK','Japan','Bagladesh','USA','Japan',\n",
    "'Russia','China', 'Kuwait','UnitedArabEmirates','Oman','SaudiArabia',\n",
    "'Bahrain','Qatar','USA','Russia', 'Austria','UK','Malaysia',\n",
    "'France','USA','Poland','Lithuania','Germany','UK','Turkey',\n",
    "'CzechRepublic','Kuwait','Vietnam','Spain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = []\n",
    "for i in list(range(df.shape[0])):\n",
    "    a = df['label'][i]\n",
    "    b = a.split('/')[5]    \n",
    "    stri = ''\n",
    "    stri = a.split('/')[0]+'/'+a.split('/')[1]+'/'+a.split('/')[2]+'/'+a.split('/')[3]+'/'+a.split('/')[4]+'/'+dest[source.index(b)]+'/'+a.split('/')[6]\n",
    "    lista.append(stri)\n",
    "    \n",
    "df['label'] = lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wybor interesujacych nas krajow - nie robimy modelu dla wszystkich\n",
    "country_model = ['China',  'France', 'Germany',  'Italy',\n",
    "       'Japan',  'Poland', 'Russia', 'Spain',\n",
    "       'Turkey', 'UK', 'USA', 'Vietnam']\n",
    "\n",
    "df = df[df[\"country\"].isin(country_model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, label = df['text_cc'], df['label'] \n",
    "X = X.reset_index(drop=True)\n",
    "label = label.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.str.replace(r\"(.)\\1{2}\", \"\")\n",
    "lista = ['china', 'russian','poland','japan','vietnam','spain','turkey','spanish','italy',\n",
    "        'france', 'french', 'russia', 'russian', 'nguyen','chinese','beijing','uk','chinese','turkish','german',\n",
    "        'tokyo','yang','polish', 'japanese', 'moscow', 'zhang', 'hanoi', 'epsrc', 'germany', 'japanese', \n",
    "         'elsevier', 'universidad', 'mineco', 'madrid', 'california', 'unite', 'michael', 'chi', \n",
    "         'minh', 'shanghai', 'anr', 'italian', 'fernandez', 'gonzalez', 'vietnamese', 'italian', 'warsaw', \n",
    "         'barcelona', 'universite', 'cnrs', 'universitat', 'grant', 'university', 'foundation', 'garcia',\n",
    "         'universita', 'rome', 'de la', 'jose', 'academic', 'press', 'national', 'journal', 'ministry'\n",
    "        ]\n",
    "\n",
    "X = X.apply(lambda x: \" \".join([word for word in str(x).split(\" \") if word not in lista]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=100, ngram_range=(1, 3))\n",
    "X_new = vectorizer.fit_transform(X)\n",
    "X_new = pd.DataFrame(X_new.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6407, 47015)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer_123gram.h5']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(vectorizer, \"vectorizer_123gram.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new['_label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zapis\n",
    "X_new.to_pickle(\"123gram.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "\n",
    "#t = pd.read_pickle(\"123gram.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6407, 47091)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#t.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
