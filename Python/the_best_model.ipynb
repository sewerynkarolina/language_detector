{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from joblib import dump, load\n",
    "import json\n",
    "from joblib import load\n",
    "\n",
    "\n",
    "def df_merge(list_of_df, on):\n",
    "    \"\"\"\n",
    "    Funkcja do łączenia dataframów z listy po kolumnie on\n",
    "    \"\"\"\n",
    "    new_df = list_of_df[0]\n",
    "    for i in list_of_df[1:]:\n",
    "        new_df = new_df.merge(i, on = on)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "def _label_to_country(df):\n",
    "    \"\"\"\n",
    "    Jeżeli mamy w planach mergowanie to to funkcja po zmergowaniu\n",
    "    Przyjmuje df z id: _label i zamieniam na _country\n",
    "    \"\"\"\n",
    "    countries = []\n",
    "    for i in df['_label']:\n",
    "        countries.append(i.split('/')[5])\n",
    "    df['_country']=countries\n",
    "    df = df.drop(\"_label\", axis=1)\n",
    "    return df\n",
    "    \n",
    "def log_model(df,test_size,model_path):\n",
    "    \"\"\"\n",
    "    Buduje model logistystyczny z penalty = l1, na podstawie df - dataframu\n",
    "    Wpisujemy też wielkość próby testowej\n",
    "    Funkcja zwraca dwa Seriesy z etykietami proby testowej i etykietami przewidywanymi przez model\n",
    "    model_path - ścieżka gdzie chcemy zapisać model wraz z jego nazwą\n",
    "    Zapisuje kolumny modelu do pliku json\n",
    "    \"\"\"\n",
    "    X = df.drop(\"_country\",axis=1)\n",
    "    y = df['_country'].astype('category').cat.codes\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=test_size, random_state=142)\n",
    "    clf = LogisticRegression(C=0.01, penalty='l1', tol=0.01, solver='saga')#zmiana zeby szybciej liczyc i mniej zmniennych\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    dump(clf, model_path + '.joblib')\n",
    "\n",
    "    with open(model_path + 'columns.json', \"w\") as f:\n",
    "        json.dump(list(df.drop('_country', axis=1 ).columns), f)\n",
    "\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    \n",
    "    return y_test, y_pred, y_train, y_pred_train\n",
    "\n",
    "def confu_matrix_for_categories(df,y_test,y_pred,path,label_column='_country'):\n",
    "    \"\"\"\n",
    "    Funkcja która, zrobi macierz gdy naszy predyktory są intami (nie krajami!)\n",
    "    Przyjmuje df - wczytaną macierz wraz z \n",
    "    label_column - kolumną labelek\n",
    "    \"\"\"\n",
    "    mark = pd.DataFrame(list(df['_country']),list(df['_country'].astype('category').cat.codes)).drop_duplicates()\n",
    "    mark = mark.to_dict()[0]\n",
    "    \n",
    "    y_test =pd.DataFrame(y_test)\n",
    "    y_test = y_test.replace({0: mark})\n",
    "    \n",
    "    y_pred =pd.DataFrame(y_pred)\n",
    "    y_pred = y_pred.replace({0: mark})\n",
    "    \n",
    "    countries = list(np.unique(df['_country'].values))\n",
    "    matrix = pd.DataFrame(confusion_matrix(y_test, y_pred, labels=countries), columns=countries, index=countries)\n",
    "    pd.DataFrame(matrix).to_csv(path)\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "def accuracy_and_f1(y_test, y_pred,y_train,y_pred_train,path):\n",
    "    \"\"\"\n",
    "    Wyświetla accuracy i f1 w modelu\n",
    "    \"\"\"\n",
    "    acc_test = np.round(sum(y_test==y_pred)/len(y_test),2)\n",
    "    acc_train = np.round(sum(y_train==y_pred_train)/len(y_train),2)\n",
    "    f1 = np.round(f1_score(y_test, y_pred, average='macro'),2)\n",
    "    stats=pd.DataFrame([acc_test,acc_train,f1])\n",
    "    stats.index=['acc_test','acc_train','f_score']\n",
    "    stats.columns=['value']\n",
    "    stats.to_csv(path)\n",
    "    \n",
    "def print_coef_for_predict(model, columns, predicted_value, how_many,path):\n",
    "    \"\"\"\n",
    "    Funkcja, która printuje how_many współczynników które wpłynęły na przewidzianą wartość\n",
    "    Przyjmuje model na którym przewidujemy, predicted_value i liczbę pierwszych predyktorów\n",
    "    i columns - predyktory na których przewidywał\n",
    "    \"\"\"\n",
    "    val = pd.DataFrame(pd.DataFrame(model.coef_).iloc[predicted_value]).values\n",
    "    df = pd.DataFrame(val[0],columns).sort_values(by = 0, ascending = False).head(how_many).rename({0:'value'}, axis= 'columns')\n",
    "    df.to_csv(path)\n",
    "\n",
    "    \n",
    "def print_coef_for_predict2(model, columns, predicted_value, how_many):\n",
    "    \"\"\"\n",
    "    Funkcja, która printuje how_many współczynników które wpłynęły na przewidzianą wartość\n",
    "    Przyjmuje model na którym przewidujemy, predicted_value i liczbę pierwszych predyktorów\n",
    "    i columns - predyktory na których przewidywał\n",
    "    \"\"\"\n",
    "    val = pd.DataFrame(pd.DataFrame(model.coef_).iloc[predicted_value]).values\n",
    "    df = pd.DataFrame(val[0],columns).sort_values(by = 0, ascending = False).head(how_many).rename({0:'value'}, axis= 'columns')\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kaja\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\users\\kaja\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "c:\\users\\kaja\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df123=pd.read_pickle(\"./Datasets/123gram.pkl\")\n",
    "df123=_label_to_country(df123)\n",
    "y_test, t_pred , y_train, y_pred_train= log_model(df123, 0.5, './modele/_model123')\n",
    "confu_matrix_for_categories(df123, y_test, t_pred, './modele/_model123conf_matrix.csv')\n",
    "accuracy_and_f1(y_test, t_pred,y_train,y_pred_train, './modele/_stats123.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = load('./modele/_model123.joblib')\n",
    "print_coef_for_predict(mod,df123.drop('_country',axis=1).columns, [9], 10,'./modele/_model123important_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>natural science</th>\n",
       "      <td>0.129008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural science of</th>\n",
       "      <td>0.123930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the natural science</th>\n",
       "      <td>0.111779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by the natural</th>\n",
       "      <td>0.097914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science of</th>\n",
       "      <td>0.095535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science of under</th>\n",
       "      <td>0.062919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science of no</th>\n",
       "      <td>0.060734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key laboratory</th>\n",
       "      <td>0.060089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key laboratory of</th>\n",
       "      <td>0.057527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>research fund for</th>\n",
       "      <td>0.048531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laboratory of</th>\n",
       "      <td>0.047373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state key</th>\n",
       "      <td>0.045302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>research fund</th>\n",
       "      <td>0.044988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school of</th>\n",
       "      <td>0.041361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fund for the</th>\n",
       "      <td>0.041299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>can get</th>\n",
       "      <td>0.039116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanwhile</th>\n",
       "      <td>0.037215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and achieve</th>\n",
       "      <td>0.037088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work be support</th>\n",
       "      <td>0.036859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>find that the</th>\n",
       "      <td>0.036543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>can not only</th>\n",
       "      <td>0.036177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>province</th>\n",
       "      <td>0.035949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of under</th>\n",
       "      <td>0.035522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we can get</th>\n",
       "      <td>0.035462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compare with</th>\n",
       "      <td>0.035366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recent years</th>\n",
       "      <td>0.034811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fundamental research</th>\n",
       "      <td>0.034699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school of computer</th>\n",
       "      <td>0.033712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>li et al</th>\n",
       "      <td>0.033082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>li et</th>\n",
       "      <td>0.032744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fund for</th>\n",
       "      <td>0.032654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>can effectively</th>\n",
       "      <td>0.031674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in recent years</th>\n",
       "      <td>0.031122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key research</th>\n",
       "      <td>0.030685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>can find that</th>\n",
       "      <td>0.029981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gradually</th>\n",
       "      <td>0.029945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doiorg jneucom</th>\n",
       "      <td>0.029931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https doiorg jneucom</th>\n",
       "      <td>0.029931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to further</th>\n",
       "      <td>0.029718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>part by the</th>\n",
       "      <td>0.029241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greatly</th>\n",
       "      <td>0.028996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in recent</th>\n",
       "      <td>0.028909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mainly</th>\n",
       "      <td>0.028716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wang</th>\n",
       "      <td>0.028591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanwhile the</th>\n",
       "      <td>0.028565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the research of</th>\n",
       "      <td>0.028532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accord to the</th>\n",
       "      <td>0.028446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compare with other</th>\n",
       "      <td>0.028201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the rapid development</th>\n",
       "      <td>0.028116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>can obtain</th>\n",
       "      <td>0.027880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          value\n",
       "natural science        0.129008\n",
       "natural science of     0.123930\n",
       "the natural science    0.111779\n",
       "by the natural         0.097914\n",
       "science of             0.095535\n",
       "science of under       0.062919\n",
       "science of no          0.060734\n",
       "key laboratory         0.060089\n",
       "key laboratory of      0.057527\n",
       "research fund for      0.048531\n",
       "laboratory of          0.047373\n",
       "state key              0.045302\n",
       "research fund          0.044988\n",
       "school of              0.041361\n",
       "fund for the           0.041299\n",
       "can get                0.039116\n",
       "meanwhile              0.037215\n",
       "and achieve            0.037088\n",
       "work be support        0.036859\n",
       "find that the          0.036543\n",
       "can not only           0.036177\n",
       "province               0.035949\n",
       "of under               0.035522\n",
       "we can get             0.035462\n",
       "compare with           0.035366\n",
       "recent years           0.034811\n",
       "fundamental research   0.034699\n",
       "school of computer     0.033712\n",
       "li et al               0.033082\n",
       "li et                  0.032744\n",
       "fund for               0.032654\n",
       "can effectively        0.031674\n",
       "in recent years        0.031122\n",
       "key research           0.030685\n",
       "can find that          0.029981\n",
       "gradually              0.029945\n",
       "doiorg jneucom         0.029931\n",
       "https doiorg jneucom   0.029931\n",
       "to further             0.029718\n",
       "part by the            0.029241\n",
       "greatly                0.028996\n",
       "in recent              0.028909\n",
       "mainly                 0.028716\n",
       "wang                   0.028591\n",
       "meanwhile the          0.028565\n",
       "the research of        0.028532\n",
       "accord to the          0.028446\n",
       "compare with other     0.028201\n",
       "the rapid development  0.028116\n",
       "can obtain             0.027880"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import load\n",
    "df123=pd.read_pickle(\"./Datasets/123gram.pkl\")\n",
    "df123 = _label_to_country(df123)\n",
    "mod = load('./modele/model123.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_coef_for_predict(mod,df123.drop('_country',axis=1).columns, [1], 50,'./modele/france.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [ 'China', 'France', 'Germany', 'Italy', 'Japan', 'Poland', 'Russia',\n",
    "   'Spain', 'Turkey', 'UK',  'Vietnam', 'USA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "val=print_coef_for_predict2(mod,df123.drop('_country',axis=1).columns, [i], 50).value*10000\n",
    "words=pd.DataFrame(print_coef_for_predict2(mod,df123.drop('_country',axis=1).columns, [i], 50).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-46-df64fbf8bf9a>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-46-df64fbf8bf9a>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    words[countries[i]=pd.DataFrame(print_coef_for_predict2(mod,df123.drop('_country',axis=1).columns, [i], 50).index)\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,12):\n",
    "    val[countries[i]]=(print_coef_for_predict2(mod,df123.drop('_country',axis=1).columns, [i], 50).value*10000)\n",
    "    words[countries[i]=pd.DataFrame(print_coef_for_predict2(mod,df123.drop('_country',axis=1).columns, [i], 50).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-052595a223e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcountries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "val\n",
    "val[countries(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>consist in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>indeed the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>whatever the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thank to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>we propose to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>whatever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>to take into</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>on fig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the one of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>propose to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rely on an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>be detail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rely on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>more precisely the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>these different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lead to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>the reception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>thank to the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>detail in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>problem be not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>this instance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>the interest of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>this latter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>compose of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>observations in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>more precisely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>base on an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>reception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>be then</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>signal and the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>also propose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>idea be to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>it lead to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>dedicate to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>into account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>assignment be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>of the observe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>benefit of the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>load the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>lengths and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>propose to use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>be detail in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>dedicate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>de la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>be generally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>error on the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>it correspond</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "0           consist in\n",
       "1           indeed the\n",
       "2         whatever the\n",
       "3               indeed\n",
       "4             thank to\n",
       "5        we propose to\n",
       "6                thank\n",
       "7             whatever\n",
       "8         to take into\n",
       "9               on fig\n",
       "10          the one of\n",
       "11          propose to\n",
       "12          rely on an\n",
       "13           be detail\n",
       "14             rely on\n",
       "15  more precisely the\n",
       "16     these different\n",
       "17             lead to\n",
       "18       the reception\n",
       "19        thank to the\n",
       "20           detail in\n",
       "21      problem be not\n",
       "22       this instance\n",
       "23     the interest of\n",
       "24         this latter\n",
       "25          compose of\n",
       "26     observations in\n",
       "27      more precisely\n",
       "28                rely\n",
       "29          base on an\n",
       "30           reception\n",
       "31             be then\n",
       "32      signal and the\n",
       "33        also propose\n",
       "34          idea be to\n",
       "35          it lead to\n",
       "36         dedicate to\n",
       "37        into account\n",
       "38       assignment be\n",
       "39      of the observe\n",
       "40      benefit of the\n",
       "41            load the\n",
       "42         lengths and\n",
       "43      propose to use\n",
       "44        be detail in\n",
       "45            dedicate\n",
       "46               de la\n",
       "47        be generally\n",
       "48        error on the\n",
       "49       it correspond"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=1\n",
    "pd.DataFrame(print_coef_for_predict2(mod,df123.drop('_country',axis=1).columns, [i], 50).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acc_test</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acc_train</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f_score</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  value\n",
       "0   acc_test   0.87\n",
       "1  acc_train   0.99\n",
       "2    f_score   0.86"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./modele/stats123.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Budowa modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kaja\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\users\\kaja\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# df123 = pd.read_pickle(\"./Datasets/123gram.pkl\")\n",
    "# df = _label_to_country(df123)\n",
    "# X = df.drop(\"_country\",axis=1)\n",
    "# y = df['_country'].astype('category').cat.codes\n",
    "# X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kaja\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\kaja\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import cross_val_score \n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# clf = LogisticRegression(C = 0.1, penalty='l1', tol=0.0001, solver='saga')\n",
    "# cross_val_score(clf, X, y, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
